# Single-cell resolution view of the transcriptional landscape of developing Drosophila eye.
### Data analysis scripts for the RDN-WDP project

This repository contains the Python scripts used to manipulate segmented nuclear point clouds
from the RDP-WDP project. See the [paper repository](https://github.com/HassanLab/rdn-wdp-paper)
for the license and the software description.

---

## Data reproduction
First, download all data from the [data repository](https://github.com/HassanLab/rdn-wdp-data).
We suggest placing the folders in the `rdn-wdp-data` directory. Warning: he complete datasets
are quite large (>1TB).

### Data normalization and registration
For normalizing the datasets use the [analyse2.py](analysis/analyse2.py) script. Results obtained
with this software are available in the [data repository](https://github.com/rejsmont/rdn-wdp-data)
in the samples folder. Thumbnails generated by this script are in the samples/thumbs subfolder.
Manually specified furrow files (when it was necessary) are also included in that folder.
To reproduce our results, please follow the steps below.

To begin, copy the `*_raw.csv` files and the metadata to a working directory.

`cp rdn-wdp-data/samples/*_raw.csv ./processing/`
`cp rdn-wdp-data/samples/*.yml ./processing/`

The script can be run in batch mode and in single sample mode. The batch mode is recommended
to start with as it will process most (hopefully) files automatically.

`python rdp-wdp-python/analysis/analyse2.py --dir ./processing --headless`

Some files will fail for various reasons (look into metadata quality section for hints).
You can fix most failures by specifying the sample rotation or furrow position manually.
To fix furrow detection, edit the `*_thumb_furrow_line.tif` file, using the `*_thumb_labels.tif`
and `_thumb_raw.tif` as a references. Now you can rerun the analysis for the sample of interest
using the single-sample mode:

`python rdp-wdp-python/analysis/analyse2.py --dir ./processing --headless --csv sample_raw.csv`

additional parameters that can (and should as automatic processing failed) be specified:

* `--no-flip` - do not flip the sample
* `--flip-x` - flip sample horizontally
* `--flip-y` - flip sample vertically
* `--furrow FURROW_FILE` - path to the manually specified furrow file -
 the file format is the same as `*_thumb_furrow_line.tif`

optional parameters:
* `--log` - specify loglevel
* `--headless` - run in headless mode (useful on HPC clusters)
* `--show-thumbs'` - choices are 'never', 'immediately', 'combined' - if and when to show
 computed thumbnails

### Combining the normalized datasets
For combining the normalized datasets use the [compine.py](analysis/combine.py) script.

`python rdp-wdp-python/analysis/combine.py --dir ./processing samples_combined.csv`

The script will automatically exclude unregisterable samples based on the metadata.

### Clustering nuclei

Clustering and cell type identification is performed using the [clustering.py](analysis/clustering.py) script.
The performance of the algorithm highly depends on the number of submitted samples. Running the script
with small dataset may result in error due to insufficient data for the model to converge.

`python rdp-wdp-python/analysis/clustering.py --data ./samples_combined.csv -k 6 -n 20 -r 1000 --cutoff 1.0 --outdir ./clustering`

the available parameters are:

* `--data` - normalized, combined point cloud CSV file
* `-k` - number of clusters to create
* `-n` - number of samples to include per hierarchical clustering iteration
* `-r` - number of hierarchical clustering iterations
* `--cutoff` - max distance from centroids for nuclei used to train the classifier
* `--clean` - max distance from centroids for nuclei used to train the classifier
* `--reproducible` - use fixed value (0) as a random seed for reproducibility (useful for debugging)
* `--not-reproducible` - use a random seed for PRN (default)
* `--clean` - classify only clean samples (without any contamination in TF channel)
* `--train-clean` - use only clean samples for training (without any contamination in TF channel)
* `--log` - specify loglevel

### Final analysis and figure generation

The final analysis and figure plotting is done using [figures_paper.py](analysis/figures_paper.py) script.
Unfortunately, the script currently does not accept parameters and the source has to be edited to point
to the data. Starting at line 23, there are 5 variables to set:

* `e` - figure output directory
* `d` - single directory containing raw data (hdf5 files, raw csv files, and metadata)
* `f` - path to the combined registered sample file
* `cl` - path to the clustering yml metadata file (other clustering files need to be in the same folder as this file)
* `ch` - path to ChIP-seq peak file (tsv format)

---

In case of problems with running these programs or if you find a bug, please contact R.E.
via email (addres availabale in the manuscript text), or create an issue in this repository.